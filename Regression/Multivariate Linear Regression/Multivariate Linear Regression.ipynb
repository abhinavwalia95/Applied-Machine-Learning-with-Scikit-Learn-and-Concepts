{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "Multivariate Linear Regression with Backward Elimination to have features that are significant to the model\n",
    "### Step 1: Importing required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from statsmodels.formula.api import OLS as regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reading CSV dataset to pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe = pd.read_csv(\"50_startups.csv\")\n",
    "dframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying X training data to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State\n",
       "0  165349.20       136897.80        471784.10    New York\n",
       "1  162597.70       151377.59        443898.53  California\n",
       "2  153441.51       101145.55        407934.54     Florida\n",
       "3  144372.41       118671.85        383199.62    New York\n",
       "4  142107.34        91391.77        366168.42     Florida"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_frame = dframe[dframe.columns.tolist()[:-1]]\n",
    "x_data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, copying Y data to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    192261.83\n",
       "1    191792.06\n",
       "2    191050.39\n",
       "3    182901.99\n",
       "4    166187.94\n",
       "Name: Profit, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_frame = dframe.Profit\n",
    "y_data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Label Encoding\n",
    "To convert categorical data(State) to numerical data for model fitting and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\IntelPython3\\lib\\site-packages\\pandas\\core\\generic.py:2773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend  State\n",
       "0  165349.20       136897.80        471784.10      2\n",
       "1  162597.70       151377.59        443898.53      0\n",
       "2  153441.51       101145.55        407934.54      1\n",
       "3  144372.41       118671.85        383199.62      2\n",
       "4  142107.34        91391.77        366168.42      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "x_data_frame.State = label_encoder.fit_transform(x_data_frame.State)\n",
    "x_data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To avoid multi colinearity, eliminate the relation between the encoded labels, use OneHotEncoding on encoded labels<br>\n",
    "\n",
    "**In this example, i got rid of the Dummy Variable Trap by eliminating very first column of training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,      0,      1, 165349, 136897, 471784],\n",
       "       [     1,      0,      0, 162597, 151377, 443898],\n",
       "       [     1,      1,      0, 153441, 101145, 407934],\n",
       "       [     1,      0,      1, 144372, 118671, 383199],\n",
       "       [     1,      1,      0, 142107,  91391, 366168]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_encoder = OneHotEncoder(categorical_features=[3])\n",
    "x_data = hot_encoder.fit_transform(x_data_frame).toarray()[:,1:]\n",
    "x_data = np.append(np.ones((x_data.shape[0], 1)), x_data, axis=1).astype(np.int)\n",
    "x_data[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192261, 191792, 191050, 182901, 166187])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data_frame.values.astype(np.int)\n",
    "y_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split and Fit\n",
    "In this step, i am spitting the data to test and training set for x and y repectively and then fitting the training data to the regression model. \n",
    "<br>\n",
    "In this case, we are not using scikit Regression Models because they do not provide P value information for the fitted model and thus i am making use of statsmodels in python for Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.943</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   129.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Sep 2017</td> <th>  Prob (F-statistic):</th> <td>3.91e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:11:37</td>     <th>  Log-Likelihood:    </th> <td> -421.10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   854.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    34</td>      <th>  BIC:               </th> <td>   864.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.255e+04</td> <td> 8358.564</td> <td>    5.091</td> <td> 0.000</td> <td> 2.56e+04</td> <td> 5.95e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -959.4172</td> <td> 4038.118</td> <td>   -0.238</td> <td> 0.814</td> <td>-9165.859</td> <td> 7247.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  699.3138</td> <td> 3661.573</td> <td>    0.191</td> <td> 0.850</td> <td>-6741.898</td> <td> 8140.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.7735</td> <td>    0.055</td> <td>   14.025</td> <td> 0.000</td> <td>    0.661</td> <td>    0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0329</td> <td>    0.066</td> <td>    0.495</td> <td> 0.624</td> <td>   -0.102</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0366</td> <td>    0.019</td> <td>    1.884</td> <td> 0.068</td> <td>   -0.003</td> <td>    0.076</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15.823</td> <th>  Durbin-Watson:     </th> <td>   2.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  23.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.094</td> <th>  Prob(JB):          </th> <td>9.02e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.026</td> <th>  Cond. No.          </th> <td>1.49e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.943\n",
       "Method:                 Least Squares   F-statistic:                     129.7\n",
       "Date:                Fri, 08 Sep 2017   Prob (F-statistic):           3.91e-21\n",
       "Time:                        08:11:37   Log-Likelihood:                -421.10\n",
       "No. Observations:                  40   AIC:                             854.2\n",
       "Df Residuals:                      34   BIC:                             864.3\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.255e+04   8358.564      5.091      0.000    2.56e+04    5.95e+04\n",
       "x1          -959.4172   4038.118     -0.238      0.814   -9165.859    7247.025\n",
       "x2           699.3138   3661.573      0.191      0.850   -6741.898    8140.526\n",
       "x3             0.7735      0.055     14.025      0.000       0.661       0.886\n",
       "x4             0.0329      0.066      0.495      0.624      -0.102       0.168\n",
       "x5             0.0366      0.019      1.884      0.068      -0.003       0.076\n",
       "==============================================================================\n",
       "Omnibus:                       15.823   Durbin-Watson:                   2.468\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.232\n",
       "Skew:                          -1.094   Prob(JB):                     9.02e-06\n",
       "Kurtosis:                       6.026   Cond. No.                     1.49e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n",
    "regressor = regression(exog=x_train, endog=y_train).fit()\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Building a better model with Backward Elimination\n",
    "For model for better prediction, i am making use of Backward elimination process to get rid of the features that are not really affecting the performance of the model.\n",
    "\n",
    "Backward Elimination steps:\n",
    "- Suppose a significance value, let say 5%\n",
    "- Fit the model with all features and check for a feature having P value > Significance value, otherwise finish\n",
    "- Eliminate that feature having P value > Significance value and fit the model with new feature set\n",
    "- Repeat until we get rid of all the unwanted features from the training set\n",
    "\n",
    "In this case, we get rid of x2 (refer above summary) from training set having P value of85% (0.850) and then fit the model with remaining features and check for the feature having P value > Significance value again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   166.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Sep 2017</td> <th>  Prob (F-statistic):</th> <td>2.90e-22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:11:54</td>     <th>  Log-Likelihood:    </th> <td> -421.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   852.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    35</td>      <th>  BIC:               </th> <td>   860.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.241e+04</td> <td> 8223.460</td> <td>    5.157</td> <td> 0.000</td> <td> 2.57e+04</td> <td> 5.91e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 1052.2133</td> <td> 3301.357</td> <td>    0.319</td> <td> 0.752</td> <td>-5649.897</td> <td> 7754.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.7747</td> <td>    0.054</td> <td>   14.302</td> <td> 0.000</td> <td>    0.665</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0318</td> <td>    0.065</td> <td>    0.487</td> <td> 0.630</td> <td>   -0.101</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0357</td> <td>    0.019</td> <td>    1.899</td> <td> 0.066</td> <td>   -0.002</td> <td>    0.074</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15.352</td> <th>  Durbin-Watson:     </th> <td>   2.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  21.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.093</td> <th>  Prob(JB):          </th> <td>2.28e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.836</td> <th>  Cond. No.          </th> <td>1.48e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.944\n",
       "Method:                 Least Squares   F-statistic:                     166.6\n",
       "Date:                Fri, 08 Sep 2017   Prob (F-statistic):           2.90e-22\n",
       "Time:                        08:11:54   Log-Likelihood:                -421.13\n",
       "No. Observations:                  40   AIC:                             852.3\n",
       "Df Residuals:                      35   BIC:                             860.7\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.241e+04   8223.460      5.157      0.000    2.57e+04    5.91e+04\n",
       "x1          1052.2133   3301.357      0.319      0.752   -5649.897    7754.324\n",
       "x2             0.7747      0.054     14.302      0.000       0.665       0.885\n",
       "x3             0.0318      0.065      0.487      0.630      -0.101       0.165\n",
       "x4             0.0357      0.019      1.899      0.066      -0.002       0.074\n",
       "==============================================================================\n",
       "Omnibus:                       15.352   Durbin-Watson:                   2.477\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.376\n",
       "Skew:                          -1.093   Prob(JB):                     2.28e-05\n",
       "Kurtosis:                       5.836   Cond. No.                     1.48e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.48e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train[:,[0,2,3,4,5]]\n",
    "x_test = x_test[:,[0,2,3,4,5]]\n",
    "regressor = regression(exog=x_train, endog=y_train).fit()\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we see the P value for x1 feature is way higher then significance value, then we get rid of this feature and fit the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   227.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Sep 2017</td> <th>  Prob (F-statistic):</th> <td>1.85e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:14:08</td>     <th>  Log-Likelihood:    </th> <td> -421.19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   850.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    36</td>      <th>  BIC:               </th> <td>   857.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.299e+04</td> <td> 7919.796</td> <td>    5.428</td> <td> 0.000</td> <td> 2.69e+04</td> <td> 5.91e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7788</td> <td>    0.052</td> <td>   15.003</td> <td> 0.000</td> <td>    0.674</td> <td>    0.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0294</td> <td>    0.064</td> <td>    0.458</td> <td> 0.650</td> <td>   -0.101</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0347</td> <td>    0.018</td> <td>    1.896</td> <td> 0.066</td> <td>   -0.002</td> <td>    0.072</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15.557</td> <th>  Durbin-Watson:     </th> <td>   2.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  22.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.081</td> <th>  Prob(JB):          </th> <td>1.27e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.974</td> <th>  Cond. No.          </th> <td>1.43e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     227.8\n",
       "Date:                Fri, 08 Sep 2017   Prob (F-statistic):           1.85e-23\n",
       "Time:                        08:14:08   Log-Likelihood:                -421.19\n",
       "No. Observations:                  40   AIC:                             850.4\n",
       "Df Residuals:                      36   BIC:                             857.1\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.299e+04   7919.796      5.428      0.000    2.69e+04    5.91e+04\n",
       "x1             0.7788      0.052     15.003      0.000       0.674       0.884\n",
       "x2             0.0294      0.064      0.458      0.650      -0.101       0.160\n",
       "x3             0.0347      0.018      1.896      0.066      -0.002       0.072\n",
       "==============================================================================\n",
       "Omnibus:                       15.557   Durbin-Watson:                   2.481\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.540\n",
       "Skew:                          -1.081   Prob(JB):                     1.27e-05\n",
       "Kurtosis:                       5.974   Cond. No.                     1.43e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.43e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train[:,[0,2,3,4]]\n",
    "x_test = x_test[:,[0,2,3,4]]\n",
    "regressor = regression(exog=x_train, endog=y_train).fit()\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, x2 feature has P value greater then 5%, so we will eliminate this in the following step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   349.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 08 Sep 2017</td> <th>  Prob (F-statistic):</th> <td>9.65e-25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:16:25</td>     <th>  Log-Likelihood:    </th> <td> -421.30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   848.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    37</td>      <th>  BIC:               </th> <td>   853.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.635e+04</td> <td> 2971.236</td> <td>   15.598</td> <td> 0.000</td> <td> 4.03e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7886</td> <td>    0.047</td> <td>   16.846</td> <td> 0.000</td> <td>    0.694</td> <td>    0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0326</td> <td>    0.018</td> <td>    1.860</td> <td> 0.071</td> <td>   -0.003</td> <td>    0.068</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.666</td> <th>  Durbin-Watson:     </th> <td>   2.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  20.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.030</td> <th>  Prob(JB):          </th> <td>3.39e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.847</td> <th>  Cond. No.          </th> <td>4.97e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.947\n",
       "Method:                 Least Squares   F-statistic:                     349.0\n",
       "Date:                Fri, 08 Sep 2017   Prob (F-statistic):           9.65e-25\n",
       "Time:                        08:16:25   Log-Likelihood:                -421.30\n",
       "No. Observations:                  40   AIC:                             848.6\n",
       "Df Residuals:                      37   BIC:                             853.7\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.635e+04   2971.236     15.598      0.000    4.03e+04    5.24e+04\n",
       "x1             0.7886      0.047     16.846      0.000       0.694       0.883\n",
       "x2             0.0326      0.018      1.860      0.071      -0.003       0.068\n",
       "==============================================================================\n",
       "Omnibus:                       14.666   Durbin-Watson:                   2.518\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               20.583\n",
       "Skew:                          -1.030   Prob(JB):                     3.39e-05\n",
       "Kurtosis:                       5.847   Cond. No.                     4.97e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.97e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train[:,[0,1,3]]\n",
    "x_test = x_test[:,[0,1,3]]\n",
    "regressor = regression(exog=x_train, endog=y_train).fit()\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here is very interesting point which i would like to describe and is about feature x2 having P value of 7.1% which is still greater than signficance value. But, i would not opt out from this feature to prevent meaningful data to the model.\n",
    "\n",
    "Now, i didn't find any feature to be eliminated. Thus, by now, our model is ready for prediction.\n",
    "\n",
    "Final Adjusted R<sup>2</sup> is 94.7%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
