{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "Multivariate Linear Regression with Backward Elimination to have features that are significant to the model\n",
    "### Step 1: Importing required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from statsmodels.formula.api import OLS as regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reading CSV dataset to pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe = pd.read_csv(\"50_startups.csv\")\n",
    "dframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying X training data to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State\n",
       "0  165349.20       136897.80        471784.10    New York\n",
       "1  162597.70       151377.59        443898.53  California\n",
       "2  153441.51       101145.55        407934.54     Florida\n",
       "3  144372.41       118671.85        383199.62    New York\n",
       "4  142107.34        91391.77        366168.42     Florida"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_frame = dframe[dframe.columns.tolist()[:-1]]\n",
    "x_data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, copying Y data to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    192261.83\n",
       "1    191792.06\n",
       "2    191050.39\n",
       "3    182901.99\n",
       "4    166187.94\n",
       "Name: Profit, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_frame = dframe.Profit\n",
    "y_data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Label Encoding\n",
    "To convert categorical data(State) to numerical data for model fitting and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\IntelPython3\\lib\\site-packages\\pandas\\core\\generic.py:2773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend  State\n",
       "0  165349.20       136897.80        471784.10      2\n",
       "1  162597.70       151377.59        443898.53      0\n",
       "2  153441.51       101145.55        407934.54      1\n",
       "3  144372.41       118671.85        383199.62      2\n",
       "4  142107.34        91391.77        366168.42      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "x_data_frame.State = label_encoder.fit_transform(x_data_frame.State)\n",
    "x_data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To avoid multi colinearity, eliminate the relation between the encoded labels, use OneHotEncoding on encoded labels<br>\n",
    "\n",
    "**In this example, i got rid of the Dummy Variable Trap by eliminating very first column of training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      1, 165349, 136897, 471784],\n",
       "       [     0,      0, 162597, 151377, 443898],\n",
       "       [     1,      0, 153441, 101145, 407934],\n",
       "       [     0,      1, 144372, 118671, 383199],\n",
       "       [     1,      0, 142107,  91391, 366168]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_encoder = OneHotEncoder(categorical_features=[3])\n",
    "x_data = hot_encoder.fit_transform(x_data_frame).toarray().astype(np.int)[:,1:]\n",
    "x_data[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192261, 191792, 191050, 182901, 166187])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data_frame.values.astype(np.int)\n",
    "y_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split and Fit\n",
    "In this step, i am spitting the data to test and training set for x and y repectively and then fitting the training data to the regression model. \n",
    "<br>\n",
    "In this case, we are not using scikit Regression Models because they do not provide P value information for the fitted model and thus i am making use of statsmodels in python for Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   7.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   8.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  -8.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 07 Sep 2017</td> <th>  Prob (F-statistic):</th>  <td>  1.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:40:57</td>     <th>  Log-Likelihood:    </th> <td> -432.43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   874.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    35</td>      <th>  BIC:               </th> <td>   883.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>  529.9975</td> <td> 5269.684</td> <td>    0.101</td> <td> 0.920</td> <td>-1.02e+04</td> <td> 1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td> 4999.3192</td> <td> 4661.687</td> <td>    1.072</td> <td> 0.291</td> <td>-4464.409</td> <td> 1.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.6845</td> <td>    0.068</td> <td>   10.001</td> <td> 0.000</td> <td>    0.546</td> <td>    0.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.3418</td> <td>    0.036</td> <td>    9.625</td> <td> 0.000</td> <td>    0.270</td> <td>    0.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>    0.0736</td> <td>    0.024</td> <td>    3.122</td> <td> 0.004</td> <td>    0.026</td> <td>    0.121</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.176</td> <th>  Durbin-Watson:     </th> <td>   1.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.337</td> <th>  Jarque-Bera (JB):  </th> <td>   1.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.501</td> <th>  Prob(JB):          </th> <td>   0.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.963</td> <th>  Cond. No.          </th> <td>7.98e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       7.963\n",
       "Model:                            OLS   Adj. R-squared:                  8.958\n",
       "Method:                 Least Squares   F-statistic:                    -8.005\n",
       "Date:                Thu, 07 Sep 2017   Prob (F-statistic):               1.00\n",
       "Time:                        08:40:57   Log-Likelihood:                -432.43\n",
       "No. Observations:                  40   AIC:                             874.9\n",
       "Df Residuals:                      35   BIC:                             883.3\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1           529.9975   5269.684      0.101      0.920   -1.02e+04    1.12e+04\n",
       "x2          4999.3192   4661.687      1.072      0.291   -4464.409    1.45e+04\n",
       "x3             0.6845      0.068     10.001      0.000       0.546       0.823\n",
       "x4             0.3418      0.036      9.625      0.000       0.270       0.414\n",
       "x5             0.0736      0.024      3.122      0.004       0.026       0.121\n",
       "==============================================================================\n",
       "Omnibus:                        2.176   Durbin-Watson:                   1.961\n",
       "Prob(Omnibus):                  0.337   Jarque-Bera (JB):                1.675\n",
       "Skew:                          -0.501   Prob(JB):                        0.433\n",
       "Kurtosis:                       2.963   Cond. No.                     7.98e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.98e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n",
    "regressor = regression(exog=x_train, endog=y_train).fit()\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Building a better model with Backward Elimination\n",
    "For model for better prediction, i am making use of Backward elimination process to get rid of the features that are not really affecting the performance of the model.\n",
    "\n",
    "Backward Elimination steps:\n",
    "- Suppose a significance value, let say 5%\n",
    "- Fit the model with all features and check for a feature having P value > Significance value, otherwise finish\n",
    "- Eliminate that feature having P value > Significance value and fit the model with new feature set\n",
    "- Repeat until we get rid of all the unwanted features from the training set\n",
    "\n",
    "In this case, we get rid of x1 (refer above summary) from training set having P value of 92% (0.920) and then fit the model with remaining features and check for the feature having P value > Significance value again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   7.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   8.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  -10.29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 07 Sep 2017</td> <th>  Prob (F-statistic):</th>  <td>  1.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:40:57</td>     <th>  Log-Likelihood:    </th> <td> -432.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   872.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    36</td>      <th>  BIC:               </th> <td>   879.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td> 4811.4168</td> <td> 4211.802</td> <td>    1.142</td> <td> 0.261</td> <td>-3730.514</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.6836</td> <td>    0.067</td> <td>   10.206</td> <td> 0.000</td> <td>    0.548</td> <td>    0.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.3430</td> <td>    0.033</td> <td>   10.358</td> <td> 0.000</td> <td>    0.276</td> <td>    0.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.0742</td> <td>    0.023</td> <td>    3.281</td> <td> 0.002</td> <td>    0.028</td> <td>    0.120</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.178</td> <th>  Durbin-Watson:     </th> <td>   1.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.337</td> <th>  Jarque-Bera (JB):  </th> <td>   1.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.501</td> <th>  Prob(JB):          </th> <td>   0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.961</td> <th>  Cond. No.          </th> <td>5.76e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       7.965\n",
       "Model:                            OLS   Adj. R-squared:                  8.739\n",
       "Method:                 Least Squares   F-statistic:                    -10.29\n",
       "Date:                Thu, 07 Sep 2017   Prob (F-statistic):               1.00\n",
       "Time:                        08:40:57   Log-Likelihood:                -432.44\n",
       "No. Observations:                  40   AIC:                             872.9\n",
       "Df Residuals:                      36   BIC:                             879.6\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1          4811.4168   4211.802      1.142      0.261   -3730.514    1.34e+04\n",
       "x2             0.6836      0.067     10.206      0.000       0.548       0.819\n",
       "x3             0.3430      0.033     10.358      0.000       0.276       0.410\n",
       "x4             0.0742      0.023      3.281      0.002       0.028       0.120\n",
       "==============================================================================\n",
       "Omnibus:                        2.178   Durbin-Watson:                   1.958\n",
       "Prob(Omnibus):                  0.337   Jarque-Bera (JB):                1.678\n",
       "Skew:                          -0.501   Prob(JB):                        0.432\n",
       "Kurtosis:                       2.961   Cond. No.                     5.76e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.76e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train[:,[1,2,3,4]]\n",
    "x_test = x_test[:,[1,2,3,4]]\n",
    "regressor = regression(exog=x_train, endog=y_train).fit()\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, i didn't find any feature having P value greater than Significance value. Thus, by now, our model is ready for prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
